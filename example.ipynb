{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106efdc9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here I will explain about the different creativity tests I implemented, as well as how to use the repo to test your own models. I will include code and hopefully plot some cool results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e50778",
   "metadata": {},
   "source": [
    "# Text Modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec0981",
   "metadata": {},
   "source": [
    "## Divergent Association Task (DAT)\n",
    "This is a creativity test where a person/LLM is asked to name 10 words that are as different from each other as possible. \\\n",
    "Here is the actual prompt I ask the LLMs to answer:\n",
    "\n",
    "''' \\\n",
    "**Please enter 10 words that are as different from each other as possible, \\\n",
    "in all meanings and uses of the words. Rules: Only single words in English. \\\n",
    "Only nouns (e.g., things, objects, concepts). No proper nouns (e.g., no specific people or places). \\\n",
    "No specialized vocabulary (e.g., no technical terms). \\\n",
    "Think of the words on your own (e.g., do not just look at objects in your surroundings). \\\n",
    "Make a list of these 10 words, a single word in each entry of the list. \\\n",
    "Do not write anything else, but the 10 words.** \\\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82d909",
   "metadata": {},
   "source": [
    "Let's run a simple DAT with several gemini models to explore the effect of temperature on the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd0839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from embeddings import GloVe, calculate_dat_score\n",
    "from request import Request, run_request\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7cd4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from creative_tests.DAT import DivergentAssociationTest\n",
    "\n",
    "test = DivergentAssociationTest(\n",
    "    models=[\"gemini-2.0-flash\", \"gemini-1.5-flash\"],\n",
    "    configs=[{\"temperature\": 0.5} ,{\"temperature\": 1}, {\"temperature\": 1.5}, {\"temperature\": 2}],\n",
    "    repeats=10,\n",
    "    delay=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68a159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of API calls: 80\n",
      "Estimated Time: 7.333333333333333\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (1)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_InactiveRpcError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_interceptor.py:332\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    329\u001b[39m call = \u001b[38;5;28mself\u001b[39m._interceptor.intercept_unary_unary(\n\u001b[32m    330\u001b[39m     continuation, client_call_details, request\n\u001b[32m    331\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_channel.py:440\u001b[39m, in \u001b[36m_InactiveRpcError.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_channel.py:1198\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1192\u001b[39m (\n\u001b[32m   1193\u001b[39m     state,\n\u001b[32m   1194\u001b[39m     call,\n\u001b[32m   1195\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._blocking(\n\u001b[32m   1196\u001b[39m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[32m   1197\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1198\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_channel.py:1006\u001b[39m, in \u001b[36m_end_unary_response_blocking\u001b[39m\u001b[34m(state, call, with_call, deadline)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[31m_InactiveRpcError\u001b[39m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Visibility check was unavailable. Please retry the request and contact support if the problem persists\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.184.10:443 {grpc_status:14, grpc_message:\"Visibility check was unavailable. Please retry the request and contact support if the problem persists\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceUnavailable\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mServiceUnavailable\u001b[39m: 503 Visibility check was unavailable. Please retry the request and contact support if the problem persists",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/creative_tests/DAT.py:66\u001b[39m, in \u001b[36mDivergentAssociationTest.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m DAT_request = Request(\n\u001b[32m     56\u001b[39m     models=\u001b[38;5;28mself\u001b[39m.models,\n\u001b[32m     57\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m.test_prompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m     delay=\u001b[38;5;28mself\u001b[39m.delay\n\u001b[32m     61\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# 2. Get the LLM's response\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m llm_response = \u001b[43mrun_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDAT_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Export responses results\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresponses/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/request.py:141\u001b[39m, in \u001b[36mrun_request\u001b[39m\u001b[34m(request)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_request\u001b[39m(request: Request):\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModelRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/request.py:129\u001b[39m, in \u001b[36mModelRunner.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    126\u001b[39m msgs.append(HumanMessage(content=\u001b[38;5;28mself\u001b[39m.request.prompt))\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43minvoke_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     result_content = result.content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m result\n\u001b[32m    131\u001b[39m     response.setdefault(model_name, {}).setdefault(\u001b[38;5;28mstr\u001b[39m(gconf), []).append([result_content])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/request.py:81\u001b[39m, in \u001b[36minvoke_with_retry\u001b[39m\u001b[34m(llm, msgs)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;129m@retry\u001b[39m(\n\u001b[32m     70\u001b[39m     stop=stop_after_attempt(\u001b[32m5\u001b[39m),\n\u001b[32m     71\u001b[39m     wait=wait_exponential(multiplier=\u001b[32m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m=\u001b[32m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m=\u001b[32m10\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke_with_retry\u001b[39m(llm, msgs):\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1255\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1252\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1253\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1342\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1329\u001b[39m     **kwargs: Any,\n\u001b[32m   1330\u001b[39m ) -> ChatResult:\n\u001b[32m   1331\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1332\u001b[39m         messages,\n\u001b[32m   1333\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1340\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:210\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:192\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:167\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m next_sleep = _retry_error_helper(\n\u001b[32m    157\u001b[39m     exc,\n\u001b[32m    158\u001b[39m     deadline,\n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m     timeout,\n\u001b[32m    165\u001b[39m )\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_sleep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f97ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of API calls: 400\n",
      "Estimated Time: 43.333333333333336\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (1)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (2)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (3)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (4)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (5)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (6)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (7)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (8)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (9)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (10)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (11)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (12)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (13)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (14)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (15)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (16)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (17)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (18)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (19)...\n",
      "Requesting gemma-3-27b-it with config={temperature=0.5} (20)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (1)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (2)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (3)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (4)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (5)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (6)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (7)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (8)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (9)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (10)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (11)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (12)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (13)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (14)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (15)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (16)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (17)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (18)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (19)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1} (20)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (1)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (2)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (3)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (4)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (5)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (6)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (7)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (8)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (9)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (10)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (11)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (12)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (13)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (14)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (15)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (16)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (17)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (18)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (19)...\n",
      "Requesting gemma-3-27b-it with config={temperature=1.5} (20)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (1)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (2)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (3)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (4)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (5)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (6)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (7)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (8)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (9)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (10)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (11)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (12)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (13)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (14)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (15)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (16)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (17)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (18)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (19)...\n",
      "Requesting gemma-3-27b-it with config={temperature=2} (20)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (11)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (12)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (13)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (14)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (15)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (16)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (17)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (18)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (19)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=0.5} (20)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (11)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (12)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (13)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (14)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (15)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (16)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (17)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (18)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (19)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1} (20)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (11)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (12)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (13)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (14)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (15)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (16)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (17)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (18)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (19)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5} (20)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (11)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (12)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (13)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (14)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (15)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (16)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (17)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (18)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (19)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=2} (20)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (11)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (12)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (13)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (14)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (15)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (16)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (17)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (18)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (19)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=0.5} (20)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (11)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (12)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (13)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (14)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (15)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (16)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (17)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (18)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (19)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1} (20)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (11)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (12)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (13)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (14)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (15)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (16)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (17)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (18)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (19)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5} (20)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (11)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (12)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (13)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (14)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (15)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (16)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (17)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (18)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (19)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=2} (20)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (1)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (2)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (3)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (4)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (5)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (6)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (7)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (8)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (9)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (10)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (11)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (12)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (13)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (14)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (15)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (16)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (17)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (18)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (19)...\n",
      "Requesting gemini-2.0-flash with config={temperature=0.5} (20)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (1)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (2)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (3)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (4)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (5)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (6)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (7)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (8)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (9)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (10)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (11)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (12)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (13)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (14)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (15)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (16)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (17)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (18)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (19)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1} (20)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (1)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (2)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (3)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (4)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (5)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (6)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (7)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (8)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (9)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (10)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (11)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (12)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (13)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (14)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (15)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (16)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (17)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (18)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (19)...\n",
      "Requesting gemini-2.0-flash with config={temperature=1.5} (20)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (1)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (2)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (3)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (4)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (5)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (6)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (7)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (8)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (9)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (10)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (11)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (12)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (13)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (14)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (15)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (16)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (17)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (18)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (19)...\n",
      "Requesting gemini-2.0-flash with config={temperature=2} (20)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (1)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (2)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (3)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (4)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (5)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (6)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (7)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (8)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (9)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (10)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (11)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (12)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (13)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (14)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (15)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (16)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (17)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (18)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (19)...\n",
      "Requesting gemini-1.5-flash with config={temperature=0.5} (20)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (1)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (2)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (3)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (4)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (5)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (6)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (7)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (8)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (9)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (10)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (11)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (12)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (13)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (14)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (15)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (16)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (17)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (18)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (19)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1} (20)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (1)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (2)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (3)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (4)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (5)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (6)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (7)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (8)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (9)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (10)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (11)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (12)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (13)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (14)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (15)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (16)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (17)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (18)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (19)...\n",
      "Requesting gemini-1.5-flash with config={temperature=1.5} (20)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (1)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (2)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (3)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (4)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (5)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (6)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (7)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (8)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (9)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (10)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (11)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (12)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (13)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (14)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (15)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (16)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (17)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (18)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (19)...\n",
      "Requesting gemini-1.5-flash with config={temperature=2} (20)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcreative_tests\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mDAT\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DivergentAssociationTest\n\u001b[32m     13\u001b[39m test = DivergentAssociationTest(\n\u001b[32m     14\u001b[39m     models=[\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgemma-3-27b-it\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     delay=\u001b[32m6\u001b[39m,\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/creative_tests/DAT.py:104\u001b[39m, in \u001b[36mDivergentAssociationTest.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m repeat \u001b[38;5;129;01min\u001b[39;00m repeats:\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# 4-5. Get embeddings from model and calculate cosine similarity\u001b[39;00m\n\u001b[32m    103\u001b[39m     score = calculate_dat_score(embedding_model, repeat)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     scores.append(\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# store per‑model/config\u001b[39;00m\n\u001b[32m    107\u001b[39m results.setdefault(model_key, {})[emb_key] = scores\n",
      "\u001b[31mTypeError\u001b[39m: float() argument must be a string or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from embeddings import GloVe, calculate_dat_score\n",
    "from request import Request, run_request\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "from creative_tests.DAT import DivergentAssociationTest\n",
    "\n",
    "test = DivergentAssociationTest(\n",
    "    models=[\n",
    "        \"gemma-3-27b-it\",\n",
    "        \"gemini-2.5-flash-preview-05-20\",\n",
    "        \"gemini-2.5-flash-preview-04-17\",\n",
    "        \"gemini-2.0-flash\", \n",
    "        \"gemini-1.5-flash\",\n",
    "        ],\n",
    "    configs=[{\"temperature\": 0.5} ,{\"temperature\": 1}, {\"temperature\": 1.5}, {\"temperature\": 2}],\n",
    "    repeats=20,\n",
    "    delay=6,\n",
    ")\n",
    "\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa528e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of API calls: 4\n",
      "Estimated Time: 0.43333333333333335\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5, thinking_config={'thinking_budget': 512}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.5, thinking_config={'thinking_budget': 512}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.5, thinking_config={'thinking_budget': 512}} (1)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcreative_tests\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mDAT\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DivergentAssociationTest\n\u001b[32m     13\u001b[39m test = DivergentAssociationTest(\n\u001b[32m     14\u001b[39m     models=[\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash-preview-05-20\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     delay=\u001b[32m6\u001b[39m,\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/creative_tests/DAT.py:67\u001b[39m, in \u001b[36mDivergentAssociationTest.run\u001b[39m\u001b[34m(self, clean_response_file)\u001b[39m\n\u001b[32m     56\u001b[39m DAT_request = Request(\n\u001b[32m     57\u001b[39m     models=\u001b[38;5;28mself\u001b[39m.models,\n\u001b[32m     58\u001b[39m     prompt=\u001b[38;5;28mself\u001b[39m.test_prompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     delay=\u001b[38;5;28mself\u001b[39m.delay\n\u001b[32m     62\u001b[39m )\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# 2. Get the LLM's response\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m#################################################################\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m llm_response = \u001b[43mrun_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDAT_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Export responses results\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresponses/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/request.py:143\u001b[39m, in \u001b[36mrun_request\u001b[39m\u001b[34m(request)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_request\u001b[39m(request: Request):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModelRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/request.py:131\u001b[39m, in \u001b[36mModelRunner.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    128\u001b[39m msgs.append(HumanMessage(content=\u001b[38;5;28mself\u001b[39m.request.prompt))\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     result = \u001b[43minvoke_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     result_content = result.content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m result\n\u001b[32m    133\u001b[39m     response.setdefault(model_name, {}).setdefault(\u001b[38;5;28mstr\u001b[39m(gconf), []).append([result_content])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/MCTB/request.py:82\u001b[39m, in \u001b[36minvoke_with_retry\u001b[39m\u001b[34m(llm, msgs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;129m@retry\u001b[39m(\n\u001b[32m     71\u001b[39m     stop=stop_after_attempt(\u001b[32m5\u001b[39m),\n\u001b[32m     72\u001b[39m     wait=wait_exponential(multiplier=\u001b[32m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m=\u001b[32m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m=\u001b[32m10\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m )\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke_with_retry\u001b[39m(llm, msgs):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1255\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1252\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1253\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:1342\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1329\u001b[39m     **kwargs: Any,\n\u001b[32m   1330\u001b[39m ) -> ChatResult:\n\u001b[32m   1331\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1332\u001b[39m         messages,\n\u001b[32m   1333\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1340\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1341\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:210\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/langchain_google_genai/chat_models.py:192\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_interceptor.py:329\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:78\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     80\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    306\u001b[39m (\n\u001b[32m    307\u001b[39m     new_method,\n\u001b[32m    308\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     new_compression,\n\u001b[32m    313\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_channel.py:1195\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1185\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1190\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1191\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m   1192\u001b[39m     (\n\u001b[32m   1193\u001b[39m         state,\n\u001b[32m   1194\u001b[39m         call,\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/DeepLearning/lib/python3.13/site-packages/grpc/_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from embeddings import GloVe, calculate_dat_score\n",
    "from request import Request, run_request\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "from creative_tests.DAT import DivergentAssociationTest\n",
    "\n",
    "test = DivergentAssociationTest(\n",
    "    models=[\n",
    "        \"gemini-2.5-flash-preview-05-20\",\n",
    "        \"gemini-2.5-flash-preview-04-17\",\n",
    "        ],\n",
    "    configs=[{\"temperature\": 1.5, \"thinking_config\": {\"thinking_budget\": 512}}],\n",
    "    repeats=2,\n",
    "    delay=6,\n",
    ")\n",
    "\n",
    "test.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecac39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of API calls: 80\n",
      "Estimated Time: 14.0\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-05-20 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 100}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 512}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 1000}} (10)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (1)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (2)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (3)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (4)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (5)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (6)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (7)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (8)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (9)...\n",
      "Requesting gemini-2.5-flash-preview-04-17 with config={temperature=1.0, thinking_config={'thinking_budget': 2000}} (10)...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from embeddings import GloVe, calculate_dat_score\n",
    "from request import Request, run_request\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "from creative_tests.DAT import DivergentAssociationTest\n",
    "\n",
    "test = DivergentAssociationTest(\n",
    "    models=[\n",
    "        \"gemini-2.5-flash-preview-05-20\",\n",
    "        \"gemini-2.5-flash-preview-04-17\",\n",
    "        ],\n",
    "    configs=[{\"temperature\": 1.0, \"thinking_config\": {\"thinking_budget\": 100}}, \n",
    "             {\"temperature\": 1.0, \"thinking_config\": {\"thinking_budget\": 512}},\n",
    "             {\"temperature\": 1.0, \"thinking_config\": {\"thinking_budget\": 1000}},\n",
    "             {\"temperature\": 1.0, \"thinking_config\": {\"thinking_budget\": 2000}}],\n",
    "    repeats=10,\n",
    "    delay=10,\n",
    ")\n",
    "\n",
    "test.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
